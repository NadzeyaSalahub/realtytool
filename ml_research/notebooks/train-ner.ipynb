{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9a012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e376645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper as h\n",
    "import imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9104077",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cfb57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd42078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4190aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('../data/df_final_5.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc92cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105128d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = ['O', *sorted(df['ner'].explode().map(lambda x: x['label']).unique())]\n",
    "# id2label = dict(enumerate([None, *sorted(labels)]))\n",
    "# label2id = {v:k for k, v in id2label.items()}\n",
    "cl = ClassLabel(names=(label_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab33369",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ids = df.sample(frac=0.2).index.tolist()\n",
    "dataset = DatasetDict({\n",
    "    'train': Dataset.from_dict(df[['source', 'ner']].drop(index=val_ids).apply(pd.Series)),\n",
    "        'validation': Dataset.from_pandas(df[['source', 'ner']].reindex(index=val_ids).apply(pd.Series))\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d18b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2239b71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8871251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb8f3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the values for input_ids, token_type_ids, attention_mask\n",
    "def tokenize_adjust_labels(all_samples_per_split):\n",
    "#     print('all', all_samples_per_split)\n",
    "    tokenized_samples = tokenizer.batch_encode_plus(all_samples_per_split[\"source\"], is_split_into_words=False,\n",
    "                                                    return_offsets_mapping=True)\n",
    "    #tokenized_samples is not a datasets object so this alone won't work with Trainer API, hence map is used \n",
    "    #so the new keys [input_ids, labels (after adjustment)]\n",
    "    #can be added to the datasets dict for each train test validation split\n",
    "    total_adjusted_labels = []\n",
    "    print(len(tokenized_samples[\"input_ids\"]))\n",
    "    for k in range(0, len(tokenized_samples[\"input_ids\"])):\n",
    "        prev_wid = -1\n",
    "        word_ids_list = tokenized_samples.word_ids(batch_index=k)\n",
    "        offsets_list = tokenized_samples['offset_mapping'][k]\n",
    "        ents = (all_samples_per_split['ner'][k])\n",
    "        i_ent = 0\n",
    "        curr_ent = ents[i_ent]\n",
    "        adjusted_label_ids = []\n",
    "   \n",
    "        for wid, (wstart, wend) in zip(word_ids_list, offsets_list):\n",
    "            if wstart > curr_ent['endOffset'] and i_ent < len(ents) - 1:\n",
    "                i_ent += 1\n",
    "                curr_ent = ents[i_ent]\n",
    "            if(wid is None):\n",
    "                adjusted_label_ids.append(-100)\n",
    "            elif(wstart >= curr_ent['startOffset'] and wend <= curr_ent['endOffset']):\n",
    "                adjusted_label_ids.append(cl.str2int(curr_ent['label']))\n",
    "            else:\n",
    "                adjusted_label_ids.append(cl.str2int('O'))\n",
    "        \n",
    "        total_adjusted_labels.append(adjusted_label_ids)\n",
    "    tokenized_samples[\"labels\"] = total_adjusted_labels\n",
    "    return tokenized_samples\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_adjust_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2f16fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2652fcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = tokenized_dataset['train'][5]\n",
    "source = item['source']\n",
    "tokens = [item['source'][token[0]: token[1]] for token in item['offset_mapping']]\n",
    "pd.DataFrame({\n",
    "    'tokens': tokens,\n",
    "    'labels': [cl.int2str(lab) if lab != -100 else '' for lab in item['labels']]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271b2565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556a74da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "metric = load_metric(\"seqeval\")\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_names[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    flattened_results = {\n",
    "        \"overall_precision\": results[\"overall_precision\"],\n",
    "        \"overall_recall\": results[\"overall_recall\"],\n",
    "        \"overall_f1\": results[\"overall_f1\"],\n",
    "        \"overall_accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n",
    "    for k in results.keys():\n",
    "        if(k not in flattened_results.keys()):\n",
    "            flattened_results[k+\"_f1\"]=results[k][\"f1\"]\n",
    "\n",
    "    return flattened_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea0e1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589677e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\"DeepPavlov/rubert-base-cased\",\n",
    "                                                        num_labels=len(label_names))\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"../models/rubert_conv_{time.strftime('%y%m%d-%H%M')}\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=15,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps = 10,\n",
    "    report_to=\"wandb\",\n",
    "    run_name = \"rent-ner-15\",\n",
    "    save_strategy='steps',\n",
    "    save_steps=10,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "# wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01731e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3864ce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../models/rubert_conv_{time.strftime('%y%m%d-%H%M')}/val_ids.json\", 'w') as f:\n",
    "    json.dump(val_ids, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2e8176",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
